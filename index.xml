<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CopeNLU on CopeNLU</title>
    <link>https://copenlu.github.io/</link>
    <description>Recent content in CopeNLU on CopeNLU</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Pepa has been appointed as a Tenure-Track Assistant Professor</title>
      <link>https://copenlu.github.io/talk/2024_09_pepa/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/talk/2024_09_pepa/</guid>
      <description>&lt;p&gt;We are delighted to share that Pepa, who has been a key member of the CopeNLU group during her PhD and postdoctoral fellowship, is now joining us as an Assistant Professor in the Department of Computer Science at the University of Copenhagen. Pepa&amp;rsquo;s research in Natural Language Processing has made significant progress in developing explainability techniques that enhance the fairness, transparency, and accountability of machine learning models. Her research, which aims to enhance the fairness, transparency, and accountability of machine learning models, particularly in the context of large language models, has already garnered significant recognition, including two prestigious awards (&lt;a href=&#34;https://ellis.eu/news/the-ellis-phd-award-2023-recognizes-two-young-scientists-from-the-universities-in-copenhagen-and-tubingen&#34;&gt;ELLIS&lt;/a&gt;, &lt;a href=&#34;https://www.informatics-europe.org/news/849-university-of-copenhagen-phd-graduate-wins-2023-best-dissertation-award.html&#34;&gt;Informatics Europe&lt;/a&gt;) for her PhD thesis.&lt;/p&gt;

&lt;p&gt;In her new role, Pepa will not only continue her research but also contribute to DIKU’s educational initiatives, helping to provide essential data science skills to industry professionals. CopeNLU is excited to have her as a new faculty member and we look forward to her continued contributions to the academic community!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Claim Verification in the Age of Large Language Models: A Survey</title>
      <link>https://copenlu.github.io/publication/2024_arxiv_dmonte/</link>
      <pubDate>Mon, 26 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_arxiv_dmonte/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Internal Conflict to Contextual Adaptation of Language Models</title>
      <link>https://copenlu.github.io/publication/2024_arxiv_marjanovic/</link>
      <pubDate>Thu, 25 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_arxiv_marjanovic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Factuality Challenges in the Era of Large Language Models</title>
      <link>https://copenlu.github.io/publication/2024_nature_augenstein/</link>
      <pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_nature_augenstein/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Grammatical Gender&#39;s Influence on Distributional Semantics: A Causal Perspective</title>
      <link>https://copenlu.github.io/publication/2024_tacl_stanczak/</link>
      <pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_tacl_stanczak/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Revealing Fine-Grained Values and Opinions in Large Language Models</title>
      <link>https://copenlu.github.io/publication/2024_arxiv_wright/</link>
      <pubDate>Thu, 27 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_arxiv_wright/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Unified Framework for Input Feature Attribution Analysis</title>
      <link>https://copenlu.github.io/publication/2024_arxiv_sun/</link>
      <pubDate>Fri, 21 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_arxiv_sun/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Measuring and Benchmarking Large Language Models&#39; Capabilities to Generate Persuasive Language</title>
      <link>https://copenlu.github.io/publication/2024_arxiv_pauli/</link>
      <pubDate>Fri, 21 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_arxiv_pauli/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages</title>
      <link>https://copenlu.github.io/publication/2024_arxiv_ghazaryan/</link>
      <pubDate>Fri, 21 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_arxiv_ghazaryan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Participate in research on explainable fact checking</title>
      <link>https://copenlu.github.io/talk/2024_05_interviews/</link>
      <pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/talk/2024_05_interviews/</guid>
      <description>

&lt;p&gt;We are recruiting professional fact checkers to take part in an interview and/or a survey about their experiences of fact checking and fact checking technologies.&lt;/p&gt;

&lt;p&gt;If you are interested in participating in this research (interviews, surveys, or both), please complete the short online form linked below. A member of the research team will then contact you with more information about the study and taking part.&lt;/p&gt;

&lt;p&gt;Interview participants will be offered an &lt;a href=&#34;https://www.tangocard.com/reward-catalog?rewardcountries=US&amp;rewardcategory=gift+card&#34;&gt;online gift voucher&lt;/a&gt; to the value of 50 USD as compensation for their time. Participants who complete the survey will be offered an online gift voucher to the value of 15 USD. All personal data you may share will be kept confidential within the research team.&lt;/p&gt;

&lt;h2 id=&#34;p-style-text-align-center-a-href-https-forms-office-com-e-cwrtediqbf-origin-lprlink-sign-up-form-a-p&#34;&gt;&lt;p style=&#34;text-align: center;&#34;&gt;&lt;a href=&#34;https://forms.office.com/e/CwrTediqbF?origin=lprLink&#34;&gt;Sign up form&lt;/a&gt;&lt;/p&gt;&lt;/h2&gt;

&lt;h2 id=&#34;what-s-involved&#34;&gt;What’s involved?&lt;/h2&gt;

&lt;p&gt;We are conducting remote interviews (e.g., on Zoom) and online surveys with professional fact-checkers, members of the general public, and other stakeholders in the fact checking sector such as journalists and content moderators.&lt;/p&gt;

&lt;p&gt;The interviews will be 60 minutes in duration and will take place remotely via Zoom. Interview participants will be offered an online gift voucher to the value of 50 USD as compensation for their time.&lt;/p&gt;

&lt;p&gt;Participants who agree to take part in the survey will receive a link via email to an online survey in July 2024. The survey will take about 20 minutes to complete. All participants who complete the survey will be offered an online gift voucher to the value of 15 USD.&lt;/p&gt;

&lt;p&gt;All personal data will be kept confidential within the project team and always anonymised for publications and presentations. This project has received ethical approval from the University of Copenhagen Research Ethics Committee for the Faculty of Science and Faculty of Health and Medical Sciences.&lt;/p&gt;

&lt;p&gt;You can read the
&lt;a href=&#34;https://www.copenlu.com/talk/2024_05_interviews/InformationSheet_FactChecking.pdf&#34;&gt;study information sheet here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;how-do-i-take-part&#34;&gt;How do I take part?&lt;/h2&gt;

&lt;p&gt;Simply fill in &lt;a href=&#34;https://forms.office.com/e/CwrTediqbF?origin=lprLink&#34;&gt;the online form here&lt;/a&gt;, and we will get in touch with you with more information.
If you have any questions or would like more information about the project, you can contact Greta Warren at &lt;a href=&#34;mailto:grwa@di.ku.dk&#34;&gt;grwa@di.ku.dk&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;what-is-this-research-about&#34;&gt;What is this research about?&lt;/h2&gt;

&lt;p&gt;This research is part of the European Research Council-funded &lt;a href=&#34;https://cordis.europa.eu/project/id/101077481&#34;&gt;ExplainYourself project&lt;/a&gt; (grant agreement ID no. 101077481), which focuses on explainable automatic fact checking.  Explainable automatic fact checking involves developing Artificial Intelligence (AI) systems that can detect and correct false information as well as produce explanations about how a system arrived at its prediction that a particular piece of information is true or false.&lt;/p&gt;

&lt;p&gt;The aim of the current research is to understand what kinds of explanations people require when using or when impacted by automated fact checking systems, and how these information needs may differ between different groups of stakeholders. We seek to ensure that the explanations that these systems provide are truly useful to the people that interact with them.&lt;/p&gt;

&lt;h2 id=&#34;research-team&#34;&gt;Research Team:&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://gretawarren.github.io/&#34;&gt;Dr Greta Warren&lt;/a&gt; &lt;br /&gt;
&lt;em&gt;Postdoctoral Researcher, Department of Computer Science, University of Copenhagen&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://miswritings.org/&#34;&gt;Prof. Irina Shklovski&lt;/a&gt; &lt;br /&gt;
&lt;em&gt;Professor, Department of Computer Science, University of Copenhagen&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://isabelleaugenstein.github.io/&#34;&gt;Prof. Isabelle Augenstein&lt;/a&gt; (Principal Investigator)&lt;br /&gt;
&lt;em&gt;Professor, Department of Computer Science, University of Copenhagen&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods</title>
      <link>https://copenlu.github.io/publication/2024_acl_yu/</link>
      <pubDate>Wed, 29 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_acl_yu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages</title>
      <link>https://copenlu.github.io/publication/2024_acl_borenstein/</link>
      <pubDate>Tue, 28 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_acl_borenstein/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Investigating the Impact of Model Instability on Explanations and Uncertainty</title>
      <link>https://copenlu.github.io/publication/2024_acl_marjanovic/</link>
      <pubDate>Mon, 20 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_acl_marjanovic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Understanding Fine-grained Distortions in Reports of Scientific Findings</title>
      <link>https://copenlu.github.io/publication/2024_acl_wuehrl/</link>
      <pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/publication/2024_acl_wuehrl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Oustanding paper award at EACL 2024</title>
      <link>https://copenlu.github.io/talk/2024_03_eacl/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/talk/2024_03_eacl/</guid>
      <description>&lt;p&gt;We are honoured to share that our paper on measuring the fragility of natural language inference models has won an outstanding paper award at EACL 2024. The paper is based on the MSc thesis of Zhaoqi Liu, who was supervised by Isabelle Augenstein and Erik Arakelyan.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://copenlu.github.io/publication/2024_eacl_arakelyan/&#34;&gt;Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models&lt;/a&gt;.
&lt;a href=&#34;https://copenlu.github.io/authors/erik-arakelyan/&#34;&gt;Erik Arakelyan&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/zhaoqi liu/&#34;&gt;Zhaoqi Liu&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/isabelle-augenstein/&#34;&gt;Isabelle Augenstein&lt;/a&gt;.&lt;/p&gt;



&lt;div class=&#34;gallery&#34;&gt;

  
  
  
  
    
    
    
    
    
      
    
      
    
    
  &lt;a data-fancybox=&#34;gallery-gallery&#34; href=&#34;https://copenlu.github.io/talk/2024_03_eacl/gallery/award.jpg&#34; &gt;
  &lt;img src=&#34;https://copenlu.github.io/talk/2024_03_eacl/gallery/award.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  
    
    
    
    
    
      
    
      
    
    
  &lt;a data-fancybox=&#34;gallery-gallery&#34; href=&#34;https://copenlu.github.io/talk/2024_03_eacl/gallery/award2.jpg&#34; &gt;
  &lt;img src=&#34;https://copenlu.github.io/talk/2024_03_eacl/gallery/award2.jpg&#34; alt=&#34;&#34;&gt;
  &lt;/a&gt;
  

  
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>

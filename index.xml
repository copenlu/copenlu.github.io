<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CopeNLU on CopeNLU</title>
    <link>https://copenlu.github.io/</link>
    <description>Recent content in CopeNLU on CopeNLU</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A Latent-Variable Model for Intrinsic Probing</title>
      <link>https://copenlu.github.io/publication/2023_aaai_stanczak/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/publication/2023_aaai_stanczak/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Positions available in context of ERC Starting Grant project ExplainYourself</title>
      <link>https://copenlu.github.io/talk/2022_11_erc/</link>
      <pubDate>Tue, 22 Nov 2022 00:00:00 +0100</pubDate>
      
      <guid>https://copenlu.github.io/talk/2022_11_erc/</guid>
      <description>&lt;p&gt;Two PhD fellowships and two postdoc positions on explainable stance detection are available in CopeNLU. The positions are offered in the context of an &lt;a href=&#34;https://erc.europa.eu/apply-grant/starting-grant&#34;&gt;ERC Starting Grant&lt;/a&gt; on &amp;lsquo;&lt;a href=&#34;https://erc.europa.eu/news/erc-2021-starting-grants-results&#34;&gt;Explainable and Robust Automatic Fact Checking (ExplainYourself)&lt;/a&gt;&amp;rsquo;. ERC Starting Grant is a highly competitive funding program by the &lt;a href=&#34;https://erc.europa.eu/homepage&#34;&gt;European Research Council&lt;/a&gt; to support the most talented early-career scientists in Europe with funding for a period of 5 years for blue-skies research to build up or expand their research groups.&lt;/p&gt;

&lt;p&gt;ExplainYourself proposes to study explainable automatic fact checking, the task of automatically predicting the veracity of textual claims using machine learning (ML) methods, while also producing explanations about how the model arrived at the prediction. Automatic fact checking methods often use opaque deep neural network models, whose inner workings cannot easily be explained. Especially for complex tasks such as automatic fact checking, this hinders greater adoption, as it is unclear to users when the models&amp;rsquo; predictions can be trusted. Existing explainable ML methods partly overcome this by reducing the task of explanation generation to highlighting the right rationale. While a good first step, this does not fully explain how a ML model arrived at a prediction. For knowledge intensive natural language understanding (NLU) tasks such as fact checking, a ML model needs to learn complex relationships between the claim, multiple evidence documents, and common sense knowledge in addition to retrieving the right evidence. There is currently no explainability method that aims to illuminate this highly complex process. In addition, existing approaches are unable to produce diverse explanations, geared towards users with different information needs. ExplainYourself radically departs from existing work in proposing methods for explainable fact checking that more accurately reflect how fact checking models make decisions, and are useful to diverse groups of end users. It is expected that these innovations will apply to explanation generation for other knowledge-intensive NLU tasks, such as question answering or entity linking.&lt;/p&gt;

&lt;p&gt;In addition to the principle investigator, the two PhD students and postdocs, the project team will also include collaborators from CopeNLU as well as external collaborators.&lt;/p&gt;

&lt;p&gt;Read more about reasons to join us &lt;a href=&#34;https://copenlu.github.io/post/why-ucph/&#34;&gt;here&lt;/a&gt;. Two of the positions are expected to be filled for a starting date in autumn 2023, whereas the other two will be filled later during the project period. The official call is not up yet; in the meantime, you can leave your contact details &lt;a href=&#34;https://forms.office.com/r/Wp6FHGbD3Z&#34;&gt;here&lt;/a&gt;, and we will send you the application link when it is up.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Revisiting Softmax for Uncertainty Approximation in Text Classification</title>
      <link>https://copenlu.github.io/publication/2022_arxiv_holm/</link>
      <pubDate>Wed, 26 Oct 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2022_arxiv_holm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Isabelle Augenstein becomes Denmark&#39;s youngest female full professor</title>
      <link>https://copenlu.github.io/talk/2022_10_promotion/</link>
      <pubDate>Mon, 17 Oct 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/talk/2022_10_promotion/</guid>
      <description>&lt;p&gt;Isabelle Augenstein has been promoted to full professor, making her the youngest ever female full professor in Denmark. The former officially reported youngest female full professor was appointed in 2008 when she was &lt;a href=&#34;https://politiken.dk/kultur/art7382410/Danmarks-yngste-kvindelige-professor-bliver-ny-designrektor&#34;&gt;34 years old&lt;/a&gt;. Read more University of Copenhagen&amp;rsquo;s &lt;a href=&#34;https://science.ku.dk/english/press/news/2022/denmarks-youngest-female-professor-appointed-at-the-university-of-copenhagen/&#34;&gt;press release&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PhD fellowship on Explainable Machine Learning available</title>
      <link>https://copenlu.github.io/talk/2022_10_phd/</link>
      <pubDate>Fri, 14 Oct 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/talk/2022_10_phd/</guid>
      <description>&lt;p&gt;One PhD fellowship on Explainable Machine Learning is available for a start in Spring 2023. The successfull candidate will be supervised by &lt;a href=&#34;https://di.ku.dk/english/staff/?pure=en/persons/424829&#34;&gt;Christina Lioma&lt;/a&gt; and Isabelle Augenstein, and join the Information Retrieval lab at the Machine Learning section at DIKU.&lt;/p&gt;

&lt;p&gt;The full call and application link can be found &lt;a href=&#34;https://employment.ku.dk/phd/?show=153856&#34;&gt;here&lt;/a&gt;; the application deadline is 13 November 2022.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2 Papers Accepted to EMNLP 2022</title>
      <link>https://copenlu.github.io/talk/2022_11_emnlp/</link>
      <pubDate>Mon, 10 Oct 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/talk/2022_11_emnlp/</guid>
      <description>&lt;p&gt;2 papers by CopeNLU authors are accepted to appear at EMNLP 2022, which are on scholarly document understanding.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://copenlu.github.io/publication/2022_naacl_sen/&#34;&gt;Counterfactually Augmented Data and Unintended Bias: The Case of Sexism and Hate Speech Detection&lt;/a&gt;.
&lt;a href=&#34;https://copenlu.github.io/authors/indira-sen/&#34;&gt;Indira Sen&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/mattia-samory&#34;&gt;Mattia Samory&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/claudia-wagner/&#34;&gt;Claudia Wagner&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/isabelle-augenstein/&#34;&gt;Isabelle Augenstein&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://copenlu.github.io/publication/2022_emnlp_ostendorff/&#34;&gt;Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings&lt;/a&gt;.
&lt;a href=&#34;https://copenlu.github.io/authors/malte-ostendorff/&gt;Malte Ostendorff&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/nils-rethmeier/&#34;&gt;Nils Rethmeier&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/isabelle-augenstein/&#34;&gt;Isabelle Augenstein&lt;/a&gt;,
 &lt;a href=&#34;https://copenlu.github.io/authors/bela-gipp/&#34;&gt;Bela Gipp&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/georg-rehm/&#34;&gt;Georg Rehm&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Generating Fluent Fact Checking Explanations with Unsupervised Post-Editing</title>
      <link>https://copenlu.github.io/publication/2022_information_jolly/</link>
      <pubDate>Sat, 08 Oct 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2022_information_jolly/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Modeling Information Change in Science Communication with Semantically Matched Paraphrases</title>
      <link>https://copenlu.github.io/publication/2022_emnlp_wright/</link>
      <pubDate>Fri, 07 Oct 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2022_emnlp_wright/</guid>
      <description>

&lt;h3 id=&#34;code-models-and-data&#34;&gt;Code, models, and data&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;ve released all of the code, models, and data for the project to help with further research on NLP for understanding science communication. The code can be found &lt;a href=&#34;https://github.com/copenlu/scientific-information-change&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, the sentence-transformers model &lt;a href=&#34;https://huggingface.co/copenlu/spiced&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;, and the dataset &lt;a href=&#34;https://huggingface.co/datasets/copenlu/spiced&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. We&amp;rsquo;ve additionally released a lightweight python package &lt;a href=&#34;https://pypi.org/project/scientific-information-change/&#34; target=&#34;_blank&#34;&gt;scientific-information-change&lt;/a&gt;, which can be used to measure the information matching score (IMS) between scientific sentences. You can download the package as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install scientific-information-change
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings</title>
      <link>https://copenlu.github.io/publication/2022_emnlp_ostendorff/</link>
      <pubDate>Fri, 07 Oct 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2022_emnlp_ostendorff/</guid>
      <description></description>
    </item>
    
    <item>
      <title>2 Papers Accepted to Coling 2022</title>
      <link>https://copenlu.github.io/talk/2022_08_coling/</link>
      <pubDate>Sat, 01 Oct 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/talk/2022_08_coling/</guid>
      <description>&lt;p&gt;2 papers by CopeNLU authors on probing question answering models are accepted to appear at Coling 2022.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://copenlu.github.io/publication/2022_coling_choudhury_machine/&#34;&gt;Machine Reading, Fast and Slow: When Do Models &amp;lsquo;Understand&amp;rsquo; Language?&lt;/a&gt;.
&lt;a href=&#34;https://copenlu.github.io/authors/sagnik-ray-choudhury/&#34;&gt;Sagnik Ray Choudhury&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/anna-rogers/&#34;&gt;Anna Rogers&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/isabelle-augenstein/&#34;&gt;Isabelle Augenstein&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://copenlu.github.io/publication/2022_coling_choudhury_edge/&#34;&gt;Can Edge Probing Tasks Reveal Linguistic Knowledge in QA Models?&lt;/a&gt;.
&lt;a href=&#34;https://copenlu.github.io/authors/sagnik-ray-choudhury/&#34;&gt;Sagnik Ray Choudhury&lt;/a&gt;,
 &lt;a href=&#34;https://copenlu.github.io/authors/nikita-bhutani/&#34;&gt;Nikita Bhutani&lt;/a&gt;, &lt;a href=&#34;https://copenlu.github.io/authors/isabelle-augenstein/&#34;&gt;Isabelle Augenstein&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>TempEL: Linking Dynamically Evolving and Newly Emerging Entities</title>
      <link>https://copenlu.github.io/publication/2022_neurips_zaporojets/</link>
      <pubDate>Mon, 19 Sep 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2022_neurips_zaporojets/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Can Edge Probing Tasks Reveal Linguistic Knowledge in QA Models?</title>
      <link>https://copenlu.github.io/publication/2022_coling_choudhury_edge/</link>
      <pubDate>Fri, 16 Sep 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2022_coling_choudhury_edge/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine Reading, Fast and Slow: When Do Models &#39;Understand&#39; Language?</title>
      <link>https://copenlu.github.io/publication/2022_coling_choudhury_machine/</link>
      <pubDate>Fri, 16 Sep 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2022_coling_choudhury_machine/</guid>
      <description></description>
    </item>
    
    <item>
      <title>QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension</title>
      <link>https://copenlu.github.io/publication/2022_csur_rogers/</link>
      <pubDate>Tue, 13 Sep 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2022_csur_rogers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Primer on Contrastive Pretraining in Language Processing: Methods, Lessons Learned and Perspectives</title>
      <link>https://copenlu.github.io/publication/2022_csur_rethmeier/</link>
      <pubDate>Wed, 07 Sep 2022 00:00:00 +0200</pubDate>
      
      <guid>https://copenlu.github.io/publication/2022_csur_rethmeier/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>

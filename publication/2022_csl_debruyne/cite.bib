@article{DEBRUYNE2022101257,
title = {{Joint Emotion Label Space Modelling for Affect Lexica}},
journal = {Computer Speech & Language},
volume = {71},
pages = {101257},
year = {2022},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2021.101257},
url = {https://www.sciencedirect.com/science/article/pii/S0885230821000644},
author = {Luna {De Bruyne} and Pepa Atanasova and Isabelle Augenstein},
keywords = {NLP, Emotion detection, Emotion lexica, VAE},
abstract = {Emotion lexica are commonly used resources to combat data poverty in automatic emotion detection. However, vocabulary coverage issues, differences in construction method and discrepancies in emotion framework and representation result in a heterogeneous landscape of emotion detection resources, calling for a unified approach to utilizing them. To combat this, we present an extended emotion lexicon of 30,273 unique entries, which is a result of merging eight existing emotion lexica by means of a multi-view variational autoencoder (VAE). We showed that a VAE is a valid approach for combining lexica with different label spaces into a joint emotion label space with a chosen number of dimensions, and that these dimensions are still interpretable. We tested the utility of the unified VAE lexicon by employing the lexicon values as features in an emotion detection model. We found that the VAE lexicon outperformed individual lexica, but contrary to our expectations, it did not outperform a naive concatenation of lexica, although it did contribute to the naive concatenation when added as an extra lexicon. Furthermore, using lexicon information as additional features on top of state-of-the-art language models usually resulted in a better performance than when no lexicon information was used.}
}

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gender-bias on CopeNLU</title>
    <link>https://copenlu.github.io/tags/gender-bias/</link>
    <description>Recent content in gender-bias on CopeNLU</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Dec 2023 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://copenlu.github.io/tags/gender-bias/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>5 Papers Accepted to EMNLP 2023</title>
      <link>https://copenlu.github.io/news/5-papers-accepted-to-emnlp-2023/</link>
      <pubDate>Tue, 05 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/news/5-papers-accepted-to-emnlp-2023/</guid>
      <description>5 papers by CopeNLU authors are accepted to appear at EMNLP 2023, on topics ranging from explainability to language modelling.
Explaining Interactions Between Text Spans. Sagnik Ray Choudhury, Pepa Atanasova, Isabelle Augenstein.
Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions. Lucie-Aimée Kaffee, Arnav Arora, Isabelle Augenstein.
Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing. Lucie-Aimée Kaffee, Arnav Arora, Zeerak Talat, Isabelle Augenstein.</description>
    </item>
    
    <item>
      <title>5 Papers Accepted to EMNLP 2024</title>
      <link>https://copenlu.github.io/news/5-papers-accepted-to-emnlp-2024/</link>
      <pubDate>Tue, 07 Nov 2023 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/news/5-papers-accepted-to-emnlp-2024/</guid>
      <description>5 papers by CopeNLU authors are accepted to appear at EMNLP 2023, on topics including factuality and probing for bias.
Social Bias Probing: Fairness Benchmarking for Language Models. Marta Marchiori Manerba, Karolina Stańczak, Riccardo Guidotti, Isabelle Augenstein.
Can Transformers Learn n-gram Language Models?. Anej Svete, Nadav Borenstein, Mike Zhou, Isabelle Augenstein, Ryan Cotterell.
DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models. Sara Vera Marjanović, Haeun Yu, Pepa Atanasova, Maria Maistro, Maria Maistro, Christina Lioma, Isabelle Augenstein.</description>
    </item>
    
    <item>
      <title>3 Papers Accepted to NAACL 2022</title>
      <link>https://copenlu.github.io/news/3-papers-accepted-to-naacl-2022/</link>
      <pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/news/3-papers-accepted-to-naacl-2022/</guid>
      <description>3 papers by CopeNLU authors are accepted to appear at NAACL 2022, which are on the topics of hatespeech detection, misinformation detection and multilingual probing.
Counterfactually Augmented Data and Unintended Bias: The Case of Sexism and Hate Speech Detection. Indira Sen, Mattia Samory, Claudia Wagner, Isabelle Augenstein.
A Survey on Stance Detection for Mis- and Disinformation Identification. Momchil Hardalov, Arnav Arora, Preslav Nakov, Isabelle Augenstein.
Same Neurons, Different Languages: Probing Morphosyntax in Multilingual Pre-trained Models.</description>
    </item>
    
  </channel>
</rss>
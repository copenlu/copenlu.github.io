<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>gender-bias on CopeNLU</title>
    <link>https://copenlu.github.io/tags/gender-bias/</link>
    <description>Recent content in gender-bias on CopeNLU</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Dec 2023 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://copenlu.github.io/tags/gender-bias/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>5 Papers Accepted to EMNLP 2023</title>
      <link>https://copenlu.github.io/talk/2023_12_emnlp/</link>
      <pubDate>Tue, 05 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/talk/2023_12_emnlp/</guid>
      <description>5 papers by CopeNLU authors are accepted to appear at EMNLP 2023, on topics ranging from explainability to language modelling.
Explaining Interactions Between Text Spans. Sagnik Ray Choudhury, Pepa Atanasova, Isabelle Augenstein.
Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions. Lucie-Aimée Kaffee, Arnav Arora, Isabelle Augenstein.
Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing. Lucie-Aimée Kaffee, Arnav Arora, Zeerak Talat, Isabelle Augenstein.</description>
    </item>
    
    <item>
      <title>3 Papers Accepted to NAACL 2022</title>
      <link>https://copenlu.github.io/talk/2022_07_naacl/</link>
      <pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/talk/2022_07_naacl/</guid>
      <description>3 papers by CopeNLU authors are accepted to appear at NAACL 2022, which are on the topics of hatespeech detection, misinformation detection and multilingual probing.
Counterfactually Augmented Data and Unintended Bias: The Case of Sexism and Hate Speech Detection. Indira Sen, Mattia Samory, Claudia Wagner, Isabelle Augenstein.
A Survey on Stance Detection for Mis- and Disinformation Identification. Momchil Hardalov, Arnav Arora, Preslav Nakov, Isabelle Augenstein.
Same Neurons, Different Languages: Probing Morphosyntax in Multilingual Pre-trained Models.</description>
    </item>
    
    <item>
      <title>Gender Bias Detection</title>
      <link>https://copenlu.github.io/project/gender-bias/</link>
      <pubDate>Thu, 26 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://copenlu.github.io/project/gender-bias/</guid>
      <description>We are working on studying methods to detect gendered language automatically using unsupervised learning methods, such as variational auto-encoders. The findings of our first paper on this (Hoyle et al., 2019) have been reported by 75+ international news outlets, including Forbes.
Currently, we&amp;rsquo;re interested in expanding the above to a cross-lingual study, as well as researching the relationship between gender bias and attitudes towards entities on social media as part of a project funded by DFF.</description>
    </item>
    
  </channel>
</rss>